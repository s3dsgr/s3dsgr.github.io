

<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="keywords" content="workshop, computer vision, audio processing, computer graphics, visual learning, machine learning">

  <link rel="shortcut icon" href="static/img/site/favicon.png">

  <title>S3DSGR @ECCV24</title>
  <meta name="description" content="Scalable 3D Scene Generation and Geometric Scene Understanding, ECCV 2024 Workshop">

  <!--Open Graph Related Stuff-->
  <meta property="og:title" content="Scalable 3D Scene Generation and Geometric Scene Understanding Workshop"/>
  <meta property="og:url" content="https://multimodalitiesfor3dscenes.github.io"/>
  <meta property="og:description" content="Multimodalities for 3D Scenes, CVPR 2022 Workshop"/>
  <meta property="og:site_name" content="Multimodalities for 3D Scenes Workshop"/>
  <meta property="og:image" content="https://multimodalitiesfor3dscenes.github.io/static/img/site/teaser.jpg"/>

  <!--Twitter Card Stuff-->
  <meta name="twitter:card" content="summary_large_image"/>
  <meta name="twitter:title" content="Multimodalities for 3D Scenes Workshop"/>
  <meta name="twitter:image" content="https://multimodalitiesfor3dscenes.github.io/static/img/site/teaser.jpg">
  <meta name="twitter:url" content="https://multimodalitiesfor3dscenes.github.io"/>
  <meta name="twitter:description" content="Multimodalities for 3D Scenes, CVPR 2024 Workshop"/>

  <!-- CSS  -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="static/css/main.css" media="screen,projection">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

  <style>

    .people-pic {
      max-width: 175px;
      max-height: 175px;
      /*width:300px;*/
      /*height:300px;*/
      object-fit: cover;
      border-radius: 50%;
  }
  </style>
</head>

  <body>

    <!-- <div class="top-strip"></div> -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="container">
    
    <div class="navbar-header">
      <a class="navbar-brand" href="/"></a>
      <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>

    <div class="navbar-collapse collapse" id="navbar-main">
      <ul class="nav navbar-nav">
        <li><a href="#intro">Introduction</a></li>
        <li><a href="#cfp">Call for papers</a></li>
        <li><a href="#dates">Schedule</a></li>
        <li><a href="#speakers">Invited Speakers</a></li>
        <li><a href="#organizers">Organizers</a></li>
        <li><a href="#contact">Contact</a></li>
        <!-- <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Past Workshops <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="../CVPR2021/index.html" target="__blank">CVPR 2021</a></li>
            <li><a href="../ECCV2022/" target="__blank">ECCV 2022</a></li>
          </ul>
        </li> -->
      </ul>
    </div>

  </div>
</div>


    <div class="container">
      <div class="page-content">
          <p><br /></p>
<div class="row">
  <div class="col-xs-12">
    <center><h1>1st Workshop on Scalable 3D Scene Generation and Geometric Scene Understanding</h1></center>
    <center><h2>ECCV 2024 Workshop</h2></center>
    <!-- <center>Room W03 - October 3 (2:00 - 5:50 pm), 2023</center> -->
  </div>
</div>

<hr />


<!-- <br>
  <center>
  <h1 style="color:red"><a href="https://www.youtube.com/watch?v=gyJDGrbLknI">The <b>video recording</b> of this workshop is here!</a></h1>
  </center>
<br> -->

<!-- <div class="alert alert-info" role="alert">
  <b>Join Zoom Meeting  <a href="https://kaust.zoom.us/j/95818223470">here</a>.</b>
</div> -->



<!-- <div class="row" id="teaser">  
    <div>  
    <img src="static/img/site/teaser.jpg" style="width: 100%; height: auto;"/>
  </div>
</div> -->


<!-- <div class="col-xs-6 col-sm-6 col-md-6 col-lg-6"> 
  <img src="static/img/site/a.png">
</div>

<div class="col-xs-6 col-sm-6 col-md-6 col-lg-6"> 
  <img src="static/img/site/b.png">
</div>
 -->






<p><br /></p>
<div class="row" id="intro">
  <div class="col-xs-12">
    <h2>Introduction</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
        Large-scale geometric scene understanding is one of the most critical and long-standing research directions in computer vision, 
        with the impactful applications in autonomous driving, and robotics. Recently, there has been a surge of interest in 3D scene generation,
        driven by its wide-ranging applications in the gaming industry, augmented reality (AR), and virtual reality (VR).
        All these have been transforming our lives and enabling significant commercial opportunities. Both academia and industry have been investing heavily in pushing the
        research directions toward more efficiency and handling the large-scale scene.     </p>
    <p>
       The efficiency and quality of the large-scale reconstruction, and generation rely on the 3D representation and priors applied in solving the problem.
       Moreover, different industries such as robotics, autonomous driving and gaming industry have distinct requirements on the quality and efficiency of the obtained 3D scene structures. 
       The proposed workshop will gather top researchers and engineers from both academia and industry to discuss the future key challenges for this.
      </p>
  </div>
</div>

<p><br /></p>

<div class="row" id="cfp">
  <div class="col-xs-12">
    <h2>Call For Papers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
      <p>
        <span style="font-weight:500;">Call for papers:</span> We invite non-archival papers of up to 14 pages (in ECCV format) for work 
        on tasks related to 3D generation, reconstruction, geometric scene understanding.
        Paper topics may include but are not limited to:
      </p>
      <ul>
        <li>Scalable large-scale 3D scene generation</li>
        <li>Efficient 3D representation learning for large-scale 3D scene reconstruction </li>
        <li>Learning compositional structure of the 3D Scene, 3D scalable Object-centric learning</li>
        <li>3D Reconstruction and generation for dynamic scene (with humans and/or rigid objects such as cars)</li>
        <li>Online learning for scalable 3D scene reconstruction </li>
        <li>Foundation models for 3D geometric scene understanding</li>
        <li>3D Reconstruction and Generation for AR/VR/Robotics etc </li>
        <li>Datasets for large-scale scene reconstruction and generation with (moving objects)</li>
      </ul>
      <p>
        <span style="font-weight:500;">Submission:</span> We encourage submissions of up to 14 pages, excluding references and acknowledgements.
        The submission should be in the ECCV format.
        Reviewing will be double-blind.
        Accepted papers will be made publicly available as non-archival reports, allowing future submissions to archival conferences or journals.
        We welcome already published papers that are within the scope of the workshop (without re-formatting), including papers from the main ECCV conference.
        Please submit your paper to the following address by the deadline: 
    <!--    <span style="color:#1a1aff;font-weight:400;"><a href="mailto:multimodalities3dscenes@gmail.com">multimodalities3dscenes@gmail.com</a></span>
        Please mention in your email if your submission has already been accepted for publication (and the name of the conference). -->
      </p>
  </div>
</div>                                                                                        

<!-- <p><br /></p>
<div class="row" id="cfp">
  <div class="col-xs-12">
    <h2>Accepted Papers</h2>
  </div>
</div>
<div class="row">
  <div class="col-md-12">
    <table>
      <tbody> 
      <tr><td><a href="https://arxiv.org/abs/2212.01558">#1. PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Minghua Liu, Yinhao Zhu, Hong Cai, Shizhong Han, Zhan Ling, Fatih Porikli, Hao Su</font></td></tr>
      <tr><td><a href="https://arxiv.org/abs/2112.08359">#2. 3D Question Answering</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Shuquan Ye, Dongdong Chen, Songfang Han, Jing Liao</font></td></tr>
      <tr><td><a href="https://arxiv.org/abs/2211.11682">#3. PointCLIP V2: Prompting CLIP and GPT for Powerful 3D Open-world Learning</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Xiangyang Zhu, Renrui Zhang, Bowei He, Ziyu Guo, Ziyao Zeng, Zipeng Qin, Shanghang Zhang, Peng Gao</font></td> </tr>        
      <tr><td><a href="https://arxiv.org/abs/2211.16312">#4. PLA: Language-Driven Open-Vocabulary 3D Scene Understanding</a> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Runyu Ding, Jihan Yang, Chuhui Xue, Wenqing Zhang, Song Bai, Xiaojuan Qi</font></td></tr>
      <tr><td><a href="https://arxiv.org/abs/2303.16894">#5. ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Zoey Guo, Yiwen Tang, Ray Zhang, Dong Wang, Zhigang Wang, Bin Zhao, Xuelong Li</font></td></tr>
      <tr><td><a href="https://arxiv.org/abs/2211.15654">#6.  OpenScene: 3D Scene Understanding with Open Vocabularies</a> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Songyou Peng, Kyle Genova, Chiyu "Max" Jiang, Andrea Tagliasacchi, Marc Pollefeys, Thomas Funkhouser</font></td></tr>
      <tr><td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Kurita_RefEgo_Referring_Expression_Comprehension_Dataset_from_First-Person_Perception_of_Ego4D_ICCV_2023_paper.pdf">#7. RefEgo: Referring Expression Comprehension Dataset from First-Person Perception of Ego4D </a> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Shuhei Kurita, Naoki Katsura, Eri Onami</font></td></tr>
      <tr><td><a href="https://arxiv.org/abs/2303.12236">#8. SALAD: Part-Level Latent Diffusion for 3D Shape Generation and Manipulation</a> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Juil Koo, Seungwoo Yoo, Minh Hieu Nguyen, Minhyuk Sung</font></td></tr>
      <tr><td><a href="https://3d-vista.github.io">#9. 3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment</a> <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Ziyu Zhu, Xiaojian Ma, Yixin Chen, Zhidong Deng, Siyuan Huang, Qing Li</font></td></tr>
    </tbody></table>
  </div>

</div> -->

<p><br /></p>

<div class="row" id="dates">
  <div class="col-xs-12">
    <h2>Important Dates</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Paper submission deadline</td>
          <td>July xx, 2024</td>
        </tr>
        <tr>
          <td>Notifications to accepted papers</td>
          <td>July xx, 2024</td>
        </tr>
        <tr>
          <td>Paper camera ready</td>
          <td>August XX, 2024</td>
        </tr>
        <tr>
          <td>Workshop date</td>
          <td>September xx, 2024 </td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<p><br /></p>
<div class="row" id="schedule">
  <div class="col-xs-12">
    <h2>Schedule</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
     <table class="table table-striped">
      <tbody>
        <tr>
          <td>Welcome</td>
          <td>2:00pm - 2:05pm</td>
        </tr>
        <tr>
          <td>Invited Talk</td>
          <td>2:05pm - 2:30pm</td>
        </tr>
        <tr>
          <td>Invited Talk</td>
          <td>2:30pm - 2:55pm</td>
        </tr>
        <tr>
          <td>Poster session / Coffee break</td>
          <td>3:00pm - 3:25pm</td>
        </tr>
        <tr>
          <td>Invited Talk</td>
          <td>3:30pm - 4:00pm</td>
        </tr>
        <tr>
          <td>Invited Talk</td>
          <td>4:00pm - 4:25pm</td>
        </tr>
        <tr>
          <td>Paper spotlights</td>
          <td>4:30pm - 4:55pm</td>
        </tr>
        <tr>
          <td>Invited Talk</td>
          <td>5:00pm - 5:40pm</td>
        </tr>
        <tr>
            <td>Panel Discussion</td>
            <td>5:40pm - 5:50pm</td>
        </tr>
        <tr>
          <td>Concluding Remarks</td>
          <td>5:40pm - 5:50pm</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<p><br /></p>
<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2>Invited Speakers</h2>
  </div>
</div>

<p><br /></p>
<div class="row">
  <div class="col-md-2">
    <a href="https://people.inf.ethz.ch/marc.pollefeys//"><img class="people-pic" style="float:left;margin-right:50px;" src="speaker/mac1.jpg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://people.inf.ethz.ch/marc.pollefeys//">Marc Pollefeys</a></b> is a Professor of Computer Science at ETH Zurich and the Director of the Microsoft
      Mixed Reality and AI Lab in Zurich where he works with a team of scien-
      tists and engineers to develop advanced perception capabilities for HoloLens
      and Mixed Reality. He is best known for his work in 3D computer vision,
      having been the first to develop a software pipeline to automatically turn
      photographs into 3D models, but also works on robotics, graphics and machine learning problems.
    </p>
  </div>
</div>
<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href="https://www.cs.utoronto.ca/~fidler/"><img class="people-pic" style="float:left;margin-right:50px;" src="speaker/fidler.jpeg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://www.cs.utoronto.ca/~fidler/">Sanja Fidler</a></b>  is an Associate Professor at University of Toronto, affiliated faculty at the Vector Institute and VP of AI Research at NVIDIA, leading a
      research lab in Toronto. Prior to that, in 2012/2013, Sanja was a Research Assistant Professor at Toyota Technological Institute at Chicago. Sanjaâ€™s
      work is in the area of Computer Vision and Machine Learning, specifically
      the intersection of computer vision and graphics, 3D vision, 3D reconstruction and synthesis; and interactive methods for image annotation.
    </p>
  </div>
</div>
<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href="https://lingjie0206.github.io//"><img class="people-pic" style="float:left;margin-right:50px;" src="speaker/lingjie.jpeg" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://lingjie0206.github.io//">Lingjie Liu</a></b>  is the Aravind K. Joshi Assistant Professor in the Department of Computer and Information Science at the University of Pennsylvania, where she leads the Penn Computer Graphics Lab.
      and she is also a member of the General Robotics, Automation, Sensing \& Perception (GRASP) Lab. Previously, 
      she was a Lise Meitner Postdoctoral Research Fellow at Max Planck Institute for Informatics. She received her Ph.D. degree at the University of Hong Kong in 2019.
      Her research interests are at the interface of Computer Graphics, Computer Vision, and AI, with a focus on Neural Scene Representations, 
      Neural Rendering, Human Performance Modeling and Capture, and 3D Reconstruction. 
    </p>
  </div>
</div>
<p><br /></p>

<p><br /></p>

<p><br /></p>

<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>

<div class="row">
    <div class="col-xs-2">
        <a href="http://users.cecs.anu.edu.au/~mliu/">
          <img class="people-pic" src="orgniser/img/miaomiao.jpg" />
        </a>
        <div class="people-name">
          <a href="http://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>
          <h6>Australian National University, Australia</h6>
        </div>
      </div>

  <div class="col-xs-2">
    <a href="https://alvarezlopezjosem.github.io/">
        <img class="people-pic" src="orgniser/img/jose.jpg" />      
    </a>
    <div class="people-name">
      <a href="https://alvarezlopezjosem.github.io/">Jose M. Alvarez</a>
      <h6>NVIDIA, US</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://people.epfl.ch/mathieu.salzmann/">
      <img class="people-pic" src="orgniser/img/mathieu.jpg" />
    </a>
    <div class="people-name">
      <a href="https://people.epfl.ch/mathieu.salzmann/">Mathieu Salzmann</a>
      <h6>EPFL, Swisserland</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://sites.google.com/site/buyuliu911/home/">
      <img class="people-pic" src="orgniser/img/buyu.jpg" />
    </a>
    <div class="people-name">
      <a href="https://sites.google.com/site/buyuliu911/home/">Buyu Liu</a>
      <h6>Zhejiang University, China</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="http://users.cecs.anu.edu.au/~hongdong/">
      <img class="people-pic" src="orgniser/img/hongdong.png" />
    </a>
    <div class="people-name">
      <a href="http://users.cecs.anu.edu.au/~hongdong/">Hongdong Li</a>
      <h6>Australian National University, Australia</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <a href="https://users.cecs.anu.edu.au/~hartley//">
      <img class="people-pic" src="orgniser/img/richard.jpeg" />
    </a>
    <div class="people-name">
      <a href="https://users.cecs.anu.edu.au/~hartley//">Richard Hartley</a>
      <h6>Australian National University, Australia</h6>
    </div>
  </div>

</div>
<p><br /></p>
<p><br /></p>

<div class="row" id="contact">
  <div class="col-xs-12">
    <h2>Contact</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      To contact the organizers please use <b>S3DSGR@gmail.com</b>
    </p>
  </div>
</div>
<p><br /></p>

<hr />

<div class="row">
  <div class="col-xs-12">
    <h2>Acknowledgments</h2>
  </div>
</div>
<p><a name="/acknowledgements"></a></p>
<div class="row">
  <div class="col-xs-12">
    <p>
      Thanks to <span style="color:#1a1aff;font-weight:400;"> <a href="https://visualdialog.org/">visualdialog.org</a></span> for the webpage format.
    </p>
  </div>
</div>

      </div>
    </div>

  </body>
</html>
